{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation\n",
    "import util_data\n",
    "import util_config\n",
    "\n",
    "from maskgan.model import MaskGAN\n",
    "from msg_id_dictionary import MSGIDDictionary\n",
    "from maskgan.mask import StochasticMask\n",
    "from maskgan.dataset import MSGIDSequence\n",
    "\n",
    "from itertools import product\n",
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskGAN Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info.\n",
      "Attack-free: 0\n",
      "Heartbeat: 0\n",
      "Ping: 0\n",
      "Request: 149797\n",
      "adv_trained_gen_all_19 has been loaded.\n",
      "# of generated data (request): 50075\n"
     ]
    }
   ],
   "source": [
    "def generate_data(epoch_idx: int):\n",
    "    assert epoch_idx > 0\n",
    "    util_config.CONFIG.reload_param_config()\n",
    "    util_config.CONFIG.reload_path_config()\n",
    "    param_config = util_config.CONFIG.get_param_config()\n",
    "    path_config = util_config.CONFIG.get_path_config()\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    labels_to_generate = param_config['maskgan']['labels_to_generate']\n",
    "    seq_len = 128\n",
    "\n",
    "    label_info_list = param_config['label_info_list']\n",
    "    train_data, train_label, _, _, _, _, _ \\\n",
    "        = data_preparation.load_data(seq_len, label_info_list, 'before_aug', '', -1)\n",
    "\n",
    "    _failure_type = 'request'\n",
    "    print(f'Train Data Info.')\n",
    "    print(f'Attack-free: {(train_label == 0).sum()}')\n",
    "    print(f'Heartbeat: {(train_label == 1).sum()}')\n",
    "    print(f'Ping: {(train_label == 2).sum()}')\n",
    "    print(f'Request: {(train_label == 3).sum()}')\n",
    "\n",
    "    one_hot_label_list = []\n",
    "    for label in train_label:\n",
    "        one_hot_label = np.zeros(4)\n",
    "        one_hot_label[int(label)] = 1.0\n",
    "        one_hot_label_list.append(one_hot_label)\n",
    "    train_label = np.vstack(one_hot_label_list)\n",
    "\n",
    "    msg_id_dict = MSGIDDictionary()\n",
    "    masker = StochasticMask(0.3)\n",
    "    msg_id_sequence = MSGIDSequence(train_data, train_label, masker, msg_id_dict, DEVICE)\n",
    "\n",
    "    batch_size = 512\n",
    "    gen_hidden_size = 64\n",
    "    dis_hidden_size = 64\n",
    "    gen_lr = 0.0001\n",
    "    dis_lr = 0.005\n",
    "    seq_len = 128\n",
    "    gen_pre_epochs = 1\n",
    "    dis_pre_epochs = 1\n",
    "    adv_epochs = 1\n",
    "    n_vocabs = msg_id_dict.get_n_vocabs()\n",
    "\n",
    "    save_path = ''\n",
    "    train_dataset = msg_id_sequence\n",
    "\n",
    "    # Model\n",
    "    mask_gan = MaskGAN(train_dataset, len(label_info_list), n_vocabs, batch_size, gen_hidden_size, dis_hidden_size,\n",
    "                       gen_lr, dis_lr, seq_len, save_path, DEVICE)\n",
    "\n",
    "    # Model load\n",
    "    gan_type = f'Unrolled-0_wasserstein-False{param_config[\"exp_id\"]}'\n",
    "    maskgan_save_path = path_config['maskgan_model_save_dir_path_template'].format(f'{seq_len}', gan_type)\n",
    "    maskgan_generator_save_file_name = path_config['maskgan_generator_save_file_name'].format('all', epoch_idx)\n",
    "    generator_save_path = os.path.join(maskgan_save_path, maskgan_generator_save_file_name)\n",
    "    mask_gan.generator.load_state_dict(torch.load(generator_save_path))\n",
    "    print(f'{maskgan_generator_save_file_name} has been loaded.')\n",
    "\n",
    "    valid_n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    # Sample\n",
    "    generated_data = []\n",
    "    counter = 0\n",
    "    for input_tensor, target_tensor, mask_tensor, label_tensor in mask_gan.train_dataloader:\n",
    "        generated_tensor, _ \\\n",
    "            = mask_gan.generator.sample_data(input_tensor, target_tensor, mask_tensor, label_tensor)\n",
    "        \n",
    "        generated_npy = generated_tensor.to('cpu').numpy()\n",
    "\n",
    "        generated_npy = generated_npy[(generated_npy >= len(util_data.INT_TO_MSG_ID_CONVERTER)).sum(1) == 0]\n",
    "        generated_data.append(generated_npy)\n",
    "\n",
    "        counter += generated_npy.shape[0]\n",
    "        if counter >= param_config['maskgan']['num_of_generated_data']:\n",
    "            break\n",
    "    generated_data = np.vstack(generated_data)\n",
    "    generated_data = data_preparation._filter_unique(generated_data)\n",
    "    print(f'# of generated data ({_failure_type}): {len(generated_data)}')\n",
    "\n",
    "    # Generated data 저장\n",
    "    additional_info = f'({epoch_idx})'\n",
    "    data_type = f\"{_failure_type}_{param_config['maskgan']['num_of_generated_data']}{additional_info}.npy\"\n",
    "    generated_data_path = path_config['maskgan_generated_data_file_path_template'].format(seq_len, gan_type, data_type)\n",
    "    util_config.make_dirs(generated_data_path)\n",
    "    np.save(generated_data_path, generated_data)\n",
    "\n",
    "\n",
    "generate_data(19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RankGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info.\n",
      "Attack-free: 0\n",
      "Heartbeat: 159795\n",
      "Ping: 0\n",
      "Request: 0\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 14 18 19 20 21 22 23 24 25 26 27]\n",
      "[0.00479633 0.00478269 0.00478289 0.00479623 0.03796666 0.05147709\n",
      " 0.13030328 0.13030724 0.06867642 0.02741633 0.04452912 0.04628332\n",
      " 0.05672243 0.04721548 0.13034557 0.04720037 0.05798944 0.04722256\n",
      " 0.00240318 0.02140604 0.02140936 0.00239472 0.00957325]\n",
      "adv_trained_gen_all_19 has been loaded.\n",
      "80\n",
      "162\n",
      "243\n",
      "324\n",
      "414\n",
      "494\n",
      "589\n",
      "674\n",
      "766\n",
      "849\n",
      "927\n",
      "1014\n",
      "1109\n",
      "1190\n",
      "1278\n",
      "1357\n",
      "1444\n",
      "1520\n",
      "1601\n",
      "1693\n",
      "1768\n",
      "1849\n",
      "1932\n",
      "2021\n",
      "2103\n",
      "2187\n",
      "2280\n",
      "2355\n",
      "2451\n",
      "2540\n",
      "2627\n",
      "2704\n",
      "2790\n",
      "2876\n",
      "2961\n",
      "3048\n",
      "3139\n",
      "3227\n",
      "3316\n",
      "3400\n",
      "3479\n",
      "3566\n",
      "3650\n",
      "3737\n",
      "3822\n",
      "3903\n",
      "3985\n",
      "4056\n",
      "4130\n",
      "4205\n",
      "4302\n",
      "4382\n",
      "4469\n",
      "4550\n",
      "4634\n",
      "4717\n",
      "4803\n",
      "4900\n",
      "4993\n",
      "5077\n",
      "5156\n",
      "5240\n",
      "5317\n",
      "5396\n",
      "5468\n",
      "5537\n",
      "5621\n",
      "5709\n",
      "5793\n",
      "5880\n",
      "5970\n",
      "6050\n",
      "6138\n",
      "6229\n",
      "6315\n",
      "6407\n",
      "6489\n",
      "6569\n",
      "6658\n",
      "6746\n",
      "6840\n",
      "6913\n",
      "6996\n",
      "7068\n",
      "7155\n",
      "7240\n",
      "7331\n",
      "7425\n",
      "7501\n",
      "7579\n",
      "7658\n",
      "7747\n",
      "7818\n",
      "7903\n",
      "7987\n",
      "8076\n",
      "8160\n",
      "8254\n",
      "8339\n",
      "8422\n",
      "8515\n",
      "8604\n",
      "8688\n",
      "8771\n",
      "8857\n",
      "8939\n",
      "9029\n",
      "9124\n",
      "9209\n",
      "9295\n",
      "9387\n",
      "9469\n",
      "9558\n",
      "9643\n",
      "9727\n",
      "9816\n",
      "9896\n",
      "9987\n",
      "10076\n",
      "10169\n",
      "10256\n",
      "10344\n",
      "10428\n",
      "10507\n",
      "10589\n",
      "10672\n",
      "10753\n",
      "10843\n",
      "10924\n",
      "11006\n",
      "11087\n",
      "11176\n",
      "11261\n",
      "11352\n",
      "11435\n",
      "11529\n",
      "11612\n",
      "11695\n",
      "11796\n",
      "11877\n",
      "11969\n",
      "12056\n",
      "12135\n",
      "12224\n",
      "12304\n",
      "12394\n",
      "12486\n",
      "12557\n",
      "12649\n",
      "12724\n",
      "12813\n",
      "12907\n",
      "12994\n",
      "13083\n",
      "13171\n",
      "13258\n",
      "13352\n",
      "13432\n",
      "13511\n",
      "13606\n",
      "13693\n",
      "13774\n",
      "13867\n",
      "13952\n",
      "14041\n",
      "14118\n",
      "14205\n",
      "14288\n",
      "14369\n",
      "14451\n",
      "14526\n",
      "14612\n",
      "14703\n",
      "14787\n",
      "14864\n",
      "14952\n",
      "15040\n",
      "15117\n",
      "15216\n",
      "15299\n",
      "15384\n",
      "15465\n",
      "15546\n",
      "15628\n",
      "15717\n",
      "15798\n",
      "15889\n",
      "15979\n",
      "16072\n",
      "16158\n",
      "16245\n",
      "16329\n",
      "16411\n",
      "16493\n",
      "16564\n",
      "16652\n",
      "16731\n",
      "16819\n",
      "16907\n",
      "16989\n",
      "17079\n",
      "17174\n",
      "17249\n",
      "17338\n",
      "17416\n",
      "17501\n",
      "17578\n",
      "17666\n",
      "17746\n",
      "17839\n",
      "17925\n",
      "18007\n",
      "18093\n",
      "18176\n",
      "18262\n",
      "18356\n",
      "18437\n",
      "18518\n",
      "18602\n",
      "18697\n",
      "18783\n",
      "18870\n",
      "18965\n",
      "19049\n",
      "19139\n",
      "19229\n",
      "19310\n",
      "19392\n",
      "19481\n",
      "19571\n",
      "19652\n",
      "19731\n",
      "19841\n",
      "19936\n",
      "20013\n",
      "20090\n",
      "20185\n",
      "20279\n",
      "20373\n",
      "20465\n",
      "20550\n",
      "20638\n",
      "20725\n",
      "20814\n",
      "20902\n",
      "20983\n",
      "21077\n",
      "21155\n",
      "21240\n",
      "21323\n",
      "21420\n",
      "21498\n",
      "21586\n",
      "21667\n",
      "21745\n",
      "21826\n",
      "21913\n",
      "22004\n",
      "22088\n",
      "22175\n",
      "22268\n",
      "22350\n",
      "22433\n",
      "22526\n",
      "22605\n",
      "22683\n",
      "22766\n",
      "22846\n",
      "22932\n",
      "23016\n",
      "23102\n",
      "23187\n",
      "23285\n",
      "23376\n",
      "23466\n",
      "23546\n",
      "23625\n",
      "23724\n",
      "23809\n",
      "23894\n",
      "23977\n",
      "24067\n",
      "24156\n",
      "24244\n",
      "24328\n",
      "24418\n",
      "24506\n",
      "24587\n",
      "24658\n",
      "24745\n",
      "24840\n",
      "24926\n",
      "25006\n",
      "25099\n",
      "25178\n",
      "25268\n",
      "25354\n",
      "25443\n",
      "25533\n",
      "25619\n",
      "25701\n",
      "25790\n",
      "25876\n",
      "25964\n",
      "26045\n",
      "26126\n",
      "26217\n",
      "26305\n",
      "26388\n",
      "26481\n",
      "26578\n",
      "26663\n",
      "26748\n",
      "26833\n",
      "26923\n",
      "27011\n",
      "27098\n",
      "27176\n",
      "27259\n",
      "27336\n",
      "27416\n",
      "27501\n",
      "27576\n",
      "27659\n",
      "27735\n",
      "27820\n",
      "27913\n",
      "28011\n",
      "28095\n",
      "28190\n",
      "28283\n",
      "28366\n",
      "28449\n",
      "28528\n",
      "28602\n",
      "28688\n",
      "28773\n",
      "28859\n",
      "28931\n",
      "29012\n",
      "29102\n",
      "29196\n",
      "29277\n",
      "29371\n",
      "29458\n",
      "29538\n",
      "29622\n",
      "29713\n",
      "29806\n",
      "29902\n",
      "30001\n",
      "30086\n",
      "30168\n",
      "30260\n",
      "30348\n",
      "30428\n",
      "30506\n",
      "30595\n",
      "30692\n",
      "30774\n",
      "30850\n",
      "30931\n",
      "31026\n",
      "31103\n",
      "31183\n",
      "31277\n",
      "31357\n",
      "31435\n",
      "31518\n",
      "31617\n",
      "31704\n",
      "31788\n",
      "31872\n",
      "31955\n",
      "32031\n",
      "32123\n",
      "32216\n",
      "32314\n",
      "32402\n",
      "32484\n",
      "32560\n",
      "32646\n",
      "32731\n",
      "32816\n",
      "32902\n",
      "32994\n",
      "33084\n",
      "33171\n",
      "33249\n",
      "33336\n",
      "33420\n",
      "33515\n",
      "33608\n",
      "33696\n",
      "33781\n",
      "33883\n",
      "33965\n",
      "34053\n",
      "34130\n",
      "34209\n",
      "34297\n",
      "34383\n",
      "34462\n",
      "34551\n",
      "34642\n",
      "34727\n",
      "34818\n",
      "34901\n",
      "34981\n",
      "35073\n",
      "35164\n",
      "35243\n",
      "35326\n",
      "35424\n",
      "35507\n",
      "35586\n",
      "35684\n",
      "35771\n",
      "35853\n",
      "35934\n",
      "36026\n",
      "36113\n",
      "36187\n",
      "36274\n",
      "36363\n",
      "36455\n",
      "36530\n",
      "36620\n",
      "36705\n",
      "36783\n",
      "36873\n",
      "36955\n",
      "37039\n",
      "37127\n",
      "37220\n",
      "37300\n",
      "37377\n",
      "37454\n",
      "37525\n",
      "37608\n",
      "37692\n",
      "37775\n",
      "37862\n",
      "37944\n",
      "38024\n",
      "38112\n",
      "38193\n",
      "38270\n",
      "38359\n",
      "38439\n",
      "38525\n",
      "38603\n",
      "38692\n",
      "38769\n",
      "38858\n",
      "38947\n",
      "39031\n",
      "39118\n",
      "39198\n",
      "39284\n",
      "39372\n",
      "39446\n",
      "39523\n",
      "39605\n",
      "39691\n",
      "39779\n",
      "39865\n",
      "39950\n",
      "40035\n",
      "40125\n",
      "40215\n",
      "40306\n",
      "40390\n",
      "40476\n",
      "40566\n",
      "40664\n",
      "40760\n",
      "40855\n",
      "40939\n",
      "41033\n",
      "41118\n",
      "41207\n",
      "41290\n",
      "41369\n",
      "41453\n",
      "41535\n",
      "41614\n",
      "41696\n",
      "41779\n",
      "41861\n",
      "41954\n",
      "42044\n",
      "42129\n",
      "42214\n",
      "42310\n",
      "42395\n",
      "42482\n",
      "42569\n",
      "42659\n",
      "42744\n",
      "42825\n",
      "42910\n",
      "43007\n",
      "43081\n",
      "43177\n",
      "43270\n",
      "43345\n",
      "43425\n",
      "43515\n",
      "43594\n",
      "43671\n",
      "43753\n",
      "43843\n",
      "43922\n",
      "44004\n",
      "44085\n",
      "44173\n",
      "44262\n",
      "44341\n",
      "44428\n",
      "44513\n",
      "44601\n",
      "44682\n",
      "44775\n",
      "44853\n",
      "44932\n",
      "45020\n",
      "45103\n",
      "45187\n",
      "45271\n",
      "45352\n",
      "45445\n",
      "45532\n",
      "45619\n",
      "45703\n",
      "45788\n",
      "45866\n",
      "45946\n",
      "46036\n",
      "46121\n",
      "46206\n",
      "46287\n",
      "46368\n",
      "46445\n",
      "46529\n",
      "46615\n",
      "46709\n",
      "46797\n",
      "46878\n",
      "46962\n",
      "47051\n",
      "47135\n",
      "47223\n",
      "47307\n",
      "47391\n",
      "47472\n",
      "47564\n",
      "47644\n",
      "47737\n",
      "47819\n",
      "47908\n",
      "47998\n",
      "48082\n",
      "48168\n",
      "48257\n",
      "48345\n",
      "48440\n",
      "48527\n",
      "48616\n",
      "48701\n",
      "48777\n",
      "48863\n",
      "48944\n",
      "49030\n",
      "49112\n",
      "49200\n",
      "49271\n",
      "49353\n",
      "49434\n",
      "49520\n",
      "49600\n",
      "49688\n",
      "49786\n",
      "49873\n",
      "49959\n",
      "50037\n",
      "50125\n",
      "50208\n",
      "50291\n",
      "50377\n",
      "50458\n",
      "50543\n",
      "50638\n",
      "50714\n",
      "50790\n",
      "50879\n",
      "50954\n",
      "51034\n",
      "51111\n",
      "51202\n",
      "51295\n",
      "51378\n",
      "51471\n",
      "51556\n",
      "51641\n",
      "51728\n",
      "51818\n",
      "51905\n",
      "51989\n",
      "52080\n",
      "52166\n",
      "52255\n",
      "52341\n",
      "52423\n",
      "52503\n",
      "52590\n",
      "52675\n",
      "52761\n",
      "52850\n",
      "52930\n",
      "53023\n",
      "53116\n",
      "53199\n",
      "53282\n",
      "53365\n",
      "53453\n",
      "53531\n",
      "53607\n",
      "53689\n",
      "53767\n",
      "53851\n",
      "53935\n",
      "54018\n",
      "54102\n",
      "54178\n",
      "54259\n",
      "54350\n",
      "54426\n",
      "54512\n",
      "54607\n",
      "54695\n",
      "54778\n",
      "54860\n",
      "54948\n",
      "55032\n",
      "55117\n",
      "55200\n",
      "55283\n",
      "55372\n",
      "55451\n",
      "55532\n",
      "55609\n",
      "55692\n",
      "55784\n",
      "55869\n",
      "55950\n",
      "56036\n",
      "56122\n",
      "56202\n",
      "56297\n",
      "56380\n",
      "56461\n",
      "56546\n",
      "56635\n",
      "56721\n",
      "56817\n",
      "56895\n",
      "56985\n",
      "57079\n",
      "57165\n",
      "57248\n",
      "57346\n",
      "57434\n",
      "57520\n",
      "57596\n",
      "57689\n",
      "57782\n",
      "57867\n",
      "57946\n",
      "58029\n",
      "58119\n",
      "58201\n",
      "58278\n",
      "58363\n",
      "58439\n",
      "58518\n",
      "58599\n",
      "58679\n",
      "58762\n",
      "58843\n",
      "58922\n",
      "59006\n",
      "59092\n",
      "59178\n",
      "59264\n",
      "59351\n",
      "59434\n",
      "59515\n",
      "59598\n",
      "59675\n",
      "59769\n",
      "59862\n",
      "59953\n",
      "60044\n",
      "60118\n",
      "60200\n",
      "60284\n",
      "60356\n",
      "60440\n",
      "60530\n",
      "60623\n",
      "60712\n",
      "60810\n",
      "60902\n",
      "60997\n",
      "61092\n",
      "61187\n",
      "61274\n",
      "61359\n",
      "61437\n",
      "61525\n",
      "61619\n",
      "61696\n",
      "61784\n",
      "61879\n",
      "61972\n",
      "62062\n",
      "62148\n",
      "62240\n",
      "62336\n",
      "62429\n",
      "62518\n",
      "62599\n",
      "62689\n",
      "62782\n",
      "62857\n",
      "62944\n",
      "63025\n",
      "63116\n",
      "63190\n",
      "63275\n",
      "63355\n",
      "63444\n",
      "63526\n",
      "63614\n",
      "63700\n",
      "63778\n",
      "63868\n",
      "63955\n",
      "64039\n",
      "64119\n",
      "64198\n",
      "64285\n",
      "64369\n",
      "64464\n",
      "64552\n",
      "64640\n",
      "64731\n",
      "64831\n",
      "64915\n",
      "64994\n",
      "65087\n",
      "65174\n",
      "65255\n",
      "65326\n",
      "65414\n",
      "65498\n",
      "65584\n",
      "65678\n",
      "65755\n",
      "65846\n",
      "65927\n",
      "66021\n",
      "66111\n",
      "66193\n",
      "66274\n",
      "66351\n",
      "66437\n",
      "66523\n",
      "66598\n",
      "66685\n",
      "66767\n",
      "66858\n",
      "66946\n",
      "67027\n",
      "67111\n",
      "67195\n",
      "67285\n",
      "67375\n",
      "67457\n",
      "67539\n",
      "67630\n",
      "67719\n",
      "67800\n",
      "67882\n",
      "67966\n",
      "68053\n",
      "68136\n",
      "68225\n",
      "68306\n",
      "68388\n",
      "68470\n",
      "68565\n",
      "68659\n",
      "68750\n",
      "68842\n",
      "68927\n",
      "69020\n",
      "69104\n",
      "69190\n",
      "69272\n",
      "69352\n",
      "69435\n",
      "69525\n",
      "69609\n",
      "69698\n",
      "69793\n",
      "69881\n",
      "69971\n",
      "70065\n",
      "70145\n",
      "70237\n",
      "70328\n",
      "70410\n",
      "70496\n",
      "70586\n",
      "70672\n",
      "70753\n",
      "70844\n",
      "70920\n",
      "71005\n",
      "71095\n",
      "71180\n",
      "71270\n",
      "71354\n",
      "71438\n",
      "71525\n",
      "71610\n",
      "71700\n",
      "71783\n",
      "71874\n",
      "71958\n",
      "72042\n",
      "72118\n",
      "72208\n",
      "72289\n",
      "72372\n",
      "72458\n",
      "72542\n",
      "72626\n",
      "72710\n",
      "72801\n",
      "72882\n",
      "72953\n",
      "73029\n",
      "73116\n",
      "73196\n",
      "73287\n",
      "73375\n",
      "73460\n",
      "73545\n",
      "73631\n",
      "73716\n",
      "73805\n",
      "73889\n",
      "73977\n",
      "74069\n",
      "74159\n",
      "74241\n",
      "74334\n",
      "74420\n",
      "74513\n",
      "74608\n",
      "74696\n",
      "74780\n",
      "74872\n",
      "74956\n",
      "75055\n",
      "75138\n",
      "75226\n",
      "75308\n",
      "75385\n",
      "75467\n",
      "75553\n",
      "75635\n",
      "75731\n",
      "75811\n",
      "75892\n",
      "75974\n",
      "76066\n",
      "76150\n",
      "76236\n",
      "76326\n",
      "76411\n",
      "76501\n",
      "76586\n",
      "76671\n",
      "76762\n",
      "76845\n",
      "76935\n",
      "77020\n",
      "77100\n",
      "77186\n",
      "77277\n",
      "77363\n",
      "77451\n",
      "77529\n",
      "77606\n",
      "77688\n",
      "77772\n",
      "77859\n",
      "77948\n",
      "78031\n",
      "78119\n",
      "78204\n",
      "78289\n",
      "78379\n",
      "78465\n",
      "78553\n",
      "78650\n",
      "78739\n",
      "78826\n",
      "78914\n",
      "78998\n",
      "79082\n",
      "79173\n",
      "79261\n",
      "79354\n",
      "79449\n",
      "79530\n",
      "79620\n",
      "79708\n",
      "79793\n",
      "79883\n",
      "79977\n",
      "80062\n",
      "80146\n",
      "80235\n",
      "80321\n",
      "80413\n",
      "80490\n",
      "80576\n",
      "80655\n",
      "80741\n",
      "80829\n",
      "80910\n",
      "80993\n",
      "81086\n",
      "81159\n",
      "81241\n",
      "81325\n",
      "81407\n",
      "81496\n",
      "81575\n",
      "81656\n",
      "81738\n",
      "81827\n",
      "81904\n",
      "81982\n",
      "82079\n",
      "82161\n",
      "82250\n",
      "82337\n",
      "82425\n",
      "82504\n",
      "82599\n",
      "82678\n",
      "82761\n",
      "82846\n",
      "82937\n",
      "83011\n",
      "83095\n",
      "83172\n",
      "83261\n",
      "83359\n",
      "83444\n",
      "83526\n",
      "83607\n",
      "83696\n",
      "83797\n",
      "83880\n",
      "83967\n",
      "84062\n",
      "84155\n",
      "84244\n",
      "84329\n",
      "84424\n",
      "84511\n",
      "84599\n",
      "84679\n",
      "84764\n",
      "84849\n",
      "84935\n",
      "85023\n",
      "85108\n",
      "85183\n",
      "85264\n",
      "85350\n",
      "85433\n",
      "85520\n",
      "85610\n",
      "85690\n",
      "85764\n",
      "85848\n",
      "85941\n",
      "86033\n",
      "86117\n",
      "86204\n",
      "86293\n",
      "86373\n",
      "86458\n",
      "86529\n",
      "86607\n",
      "86707\n",
      "86788\n",
      "86878\n",
      "86967\n",
      "87046\n",
      "87128\n",
      "87208\n",
      "87298\n",
      "87378\n",
      "87465\n",
      "87548\n",
      "87641\n",
      "87725\n",
      "87808\n",
      "87886\n",
      "87963\n",
      "88038\n",
      "88124\n",
      "88217\n",
      "88285\n",
      "88367\n",
      "88455\n",
      "88542\n",
      "88622\n",
      "88714\n",
      "88797\n",
      "88886\n",
      "88969\n",
      "89051\n",
      "89134\n",
      "89217\n",
      "89299\n",
      "89399\n",
      "89482\n",
      "89569\n",
      "89663\n",
      "89754\n",
      "89837\n",
      "89924\n",
      "90011\n",
      "90088\n",
      "90170\n",
      "90256\n",
      "90332\n",
      "90419\n",
      "90507\n",
      "90597\n",
      "90677\n",
      "90753\n",
      "90843\n",
      "90935\n",
      "91028\n",
      "91115\n",
      "91190\n",
      "91284\n",
      "91371\n",
      "91456\n",
      "91538\n",
      "91621\n",
      "91706\n",
      "91790\n",
      "91878\n",
      "91966\n",
      "92053\n",
      "92130\n",
      "92210\n",
      "92293\n",
      "92379\n",
      "92451\n",
      "92539\n",
      "92625\n",
      "92703\n",
      "92794\n",
      "92878\n",
      "92960\n",
      "93040\n",
      "93130\n",
      "93218\n",
      "93298\n",
      "93380\n",
      "93458\n",
      "93537\n",
      "93625\n",
      "93705\n",
      "93791\n",
      "93877\n",
      "93964\n",
      "94057\n",
      "94133\n",
      "94224\n",
      "94296\n",
      "94379\n",
      "94468\n",
      "94550\n",
      "94641\n",
      "94717\n",
      "94804\n",
      "94893\n",
      "94969\n",
      "95047\n",
      "95133\n",
      "95222\n",
      "95316\n",
      "95393\n",
      "95469\n",
      "95563\n",
      "95654\n",
      "95739\n",
      "95827\n",
      "95908\n",
      "95991\n",
      "96073\n",
      "96149\n",
      "96252\n",
      "96341\n",
      "96425\n",
      "96513\n",
      "96599\n",
      "96688\n",
      "96783\n",
      "96871\n",
      "96958\n",
      "97044\n",
      "97131\n",
      "97203\n",
      "97285\n",
      "97366\n",
      "97462\n",
      "97541\n",
      "97624\n",
      "97707\n",
      "97788\n",
      "97879\n",
      "97956\n",
      "98043\n",
      "98133\n",
      "98207\n",
      "98292\n",
      "98378\n",
      "98464\n",
      "98550\n",
      "98644\n",
      "98727\n",
      "98814\n",
      "98898\n",
      "98978\n",
      "99076\n",
      "99157\n",
      "99245\n",
      "99328\n",
      "99403\n",
      "99487\n",
      "99568\n",
      "99652\n",
      "99732\n",
      "99828\n",
      "99907\n",
      "99991\n",
      "100075\n",
      "100162\n",
      "100239\n",
      "100327\n",
      "100412\n",
      "100488\n",
      "100569\n",
      "100661\n",
      "100737\n",
      "100823\n",
      "100902\n",
      "100993\n",
      "101069\n",
      "101153\n",
      "101233\n",
      "101312\n",
      "101412\n",
      "101495\n",
      "101574\n",
      "101658\n",
      "101739\n",
      "101833\n",
      "101920\n",
      "102003\n",
      "102082\n",
      "102166\n",
      "102251\n",
      "102329\n",
      "102413\n",
      "102490\n",
      "102578\n",
      "102664\n",
      "102757\n",
      "102837\n",
      "102928\n",
      "103014\n",
      "103102\n",
      "103189\n",
      "103267\n",
      "103347\n",
      "103436\n",
      "103528\n",
      "103610\n",
      "103684\n",
      "103754\n",
      "103842\n",
      "103932\n",
      "104019\n",
      "104115\n",
      "104208\n",
      "104292\n",
      "104381\n",
      "104454\n",
      "104537\n",
      "104619\n",
      "104708\n",
      "104807\n",
      "104901\n",
      "104992\n",
      "105081\n",
      "105162\n",
      "105255\n",
      "105345\n",
      "105431\n",
      "105516\n",
      "105608\n",
      "105699\n",
      "105777\n",
      "105858\n",
      "105942\n",
      "106029\n",
      "106118\n",
      "106202\n",
      "106276\n",
      "106362\n",
      "106448\n",
      "106525\n",
      "106610\n",
      "106693\n",
      "106776\n",
      "106865\n",
      "106950\n",
      "107043\n",
      "107133\n",
      "107226\n",
      "107311\n",
      "107401\n",
      "107498\n",
      "107587\n",
      "107663\n",
      "107743\n",
      "107832\n",
      "107913\n",
      "107996\n",
      "108079\n",
      "108158\n",
      "108249\n",
      "108340\n",
      "108420\n",
      "108501\n",
      "108585\n",
      "108670\n",
      "108755\n",
      "108826\n",
      "108911\n",
      "108989\n",
      "109068\n",
      "109168\n",
      "109256\n",
      "109344\n",
      "109426\n",
      "109508\n",
      "109602\n",
      "109689\n",
      "109779\n",
      "109861\n",
      "109944\n",
      "110027\n",
      "110113\n",
      "110201\n",
      "110283\n",
      "110362\n",
      "110450\n",
      "110536\n",
      "110609\n",
      "110690\n",
      "110771\n",
      "110851\n",
      "110937\n",
      "111020\n",
      "111101\n",
      "111184\n",
      "111275\n",
      "111359\n",
      "111446\n",
      "111520\n",
      "111603\n",
      "111684\n",
      "111770\n",
      "111856\n",
      "111951\n",
      "112046\n",
      "112131\n",
      "112214\n",
      "112302\n",
      "112382\n",
      "112460\n",
      "112551\n",
      "112648\n",
      "112734\n",
      "112820\n",
      "112902\n",
      "112986\n",
      "113073\n",
      "113172\n",
      "113260\n",
      "113349\n",
      "113429\n",
      "113518\n",
      "113611\n",
      "113699\n",
      "113783\n",
      "113874\n",
      "113963\n",
      "114050\n",
      "114129\n",
      "114214\n",
      "114294\n",
      "114387\n",
      "114477\n",
      "114564\n",
      "114645\n",
      "114722\n",
      "114809\n",
      "114887\n",
      "114976\n",
      "115061\n",
      "115148\n",
      "115226\n",
      "115308\n",
      "115401\n",
      "115491\n",
      "115574\n",
      "115661\n",
      "115746\n",
      "115833\n",
      "115927\n",
      "116016\n",
      "116101\n",
      "116183\n",
      "116261\n",
      "116341\n",
      "116418\n",
      "116504\n",
      "116579\n",
      "116667\n",
      "116746\n",
      "116832\n",
      "116918\n",
      "116999\n",
      "117089\n",
      "117174\n",
      "117256\n",
      "117335\n",
      "117415\n",
      "117499\n",
      "117587\n",
      "117689\n",
      "117795\n",
      "117878\n",
      "117967\n",
      "118051\n",
      "118133\n",
      "118216\n",
      "118297\n",
      "118383\n",
      "118475\n",
      "118571\n",
      "118643\n",
      "118739\n",
      "118829\n",
      "118905\n",
      "118992\n",
      "119079\n",
      "119176\n",
      "119263\n",
      "119347\n",
      "119422\n",
      "119503\n",
      "119587\n",
      "119674\n",
      "119752\n",
      "119841\n",
      "119929\n",
      "120008\n",
      "120080\n",
      "120172\n",
      "120269\n",
      "120359\n",
      "120454\n",
      "120536\n",
      "120634\n",
      "120728\n",
      "120801\n",
      "120880\n",
      "120962\n",
      "121046\n",
      "121128\n",
      "121207\n",
      "121290\n",
      "121373\n",
      "121462\n",
      "121544\n",
      "121636\n",
      "121724\n",
      "121800\n",
      "121890\n",
      "121979\n",
      "122062\n",
      "122161\n",
      "122254\n",
      "122334\n",
      "122419\n",
      "122517\n",
      "122610\n",
      "122689\n",
      "122783\n",
      "122863\n",
      "122946\n",
      "123036\n",
      "123126\n",
      "123217\n",
      "123312\n",
      "123394\n",
      "123490\n",
      "123576\n",
      "123663\n",
      "123744\n",
      "123842\n",
      "123923\n",
      "124008\n",
      "124095\n",
      "124178\n",
      "124258\n",
      "124332\n",
      "124413\n",
      "124499\n",
      "124584\n",
      "124674\n",
      "124751\n",
      "124830\n",
      "124915\n",
      "124997\n",
      "125079\n",
      "125152\n",
      "125242\n",
      "125324\n",
      "125415\n",
      "125506\n",
      "125597\n",
      "125679\n",
      "125760\n",
      "125849\n",
      "125934\n",
      "126015\n",
      "126096\n",
      "126184\n",
      "126275\n",
      "126370\n",
      "126454\n",
      "126527\n",
      "126612\n",
      "126693\n",
      "126783\n",
      "126865\n",
      "126955\n",
      "127038\n",
      "127127\n",
      "127200\n",
      "127288\n",
      "127365\n",
      "127443\n",
      "127518\n",
      "127609\n",
      "127696\n",
      "127784\n",
      "127868\n",
      "127954\n",
      "128047\n",
      "128119\n",
      "128198\n",
      "128305\n",
      "128382\n",
      "128471\n",
      "128570\n",
      "128659\n",
      "128734\n",
      "128822\n",
      "128901\n",
      "128986\n",
      "129068\n",
      "129143\n",
      "129234\n",
      "129319\n",
      "129403\n",
      "129482\n",
      "129562\n",
      "129647\n",
      "129737\n",
      "129823\n",
      "129906\n",
      "129989\n",
      "130075\n",
      "130163\n",
      "130243\n",
      "130329\n",
      "130416\n",
      "130497\n",
      "130578\n",
      "130661\n",
      "130745\n",
      "130832\n",
      "130916\n",
      "130995\n",
      "131083\n",
      "131165\n",
      "131252\n",
      "131344\n",
      "131436\n",
      "131520\n",
      "131605\n",
      "131685\n",
      "131768\n",
      "131850\n",
      "131936\n",
      "132022\n",
      "132106\n",
      "132185\n",
      "132268\n",
      "132353\n",
      "132439\n",
      "132519\n",
      "132609\n",
      "132686\n",
      "132775\n",
      "132870\n",
      "132962\n",
      "133042\n",
      "133132\n",
      "133219\n",
      "133297\n",
      "133386\n",
      "133464\n",
      "133553\n",
      "133633\n",
      "133720\n",
      "133809\n",
      "133893\n",
      "133982\n",
      "134062\n",
      "134142\n",
      "134228\n",
      "134316\n",
      "134398\n",
      "134478\n",
      "134560\n",
      "134657\n",
      "134744\n",
      "134832\n",
      "134915\n",
      "134994\n",
      "135075\n",
      "135148\n",
      "135240\n",
      "135327\n",
      "135401\n",
      "135487\n",
      "135568\n",
      "135660\n",
      "135744\n",
      "135835\n",
      "135929\n",
      "136007\n",
      "136088\n",
      "136180\n",
      "136260\n",
      "136359\n",
      "136454\n",
      "136547\n",
      "136624\n",
      "136697\n",
      "136777\n",
      "136861\n",
      "136955\n",
      "137030\n",
      "137111\n",
      "137195\n",
      "137286\n",
      "137382\n",
      "137459\n",
      "137547\n",
      "137626\n",
      "137718\n",
      "137808\n",
      "137895\n",
      "137975\n",
      "138062\n",
      "138143\n",
      "138232\n",
      "138319\n",
      "138393\n",
      "138481\n",
      "138569\n",
      "138654\n",
      "138747\n",
      "138841\n",
      "138923\n",
      "138999\n",
      "139078\n",
      "139162\n",
      "139240\n",
      "139323\n",
      "139415\n",
      "139506\n",
      "139588\n",
      "139665\n",
      "139748\n",
      "139833\n",
      "139923\n",
      "140014\n",
      "140106\n",
      "140191\n",
      "140269\n",
      "140343\n",
      "140429\n",
      "140515\n",
      "140605\n",
      "140681\n",
      "140772\n",
      "140855\n",
      "140933\n",
      "141022\n",
      "141098\n",
      "141180\n",
      "141260\n",
      "141347\n",
      "141441\n",
      "141530\n",
      "141613\n",
      "141698\n",
      "141792\n",
      "141878\n",
      "141958\n",
      "142039\n",
      "142120\n",
      "142212\n",
      "142303\n",
      "142391\n",
      "142477\n",
      "142568\n",
      "142655\n",
      "142735\n",
      "142816\n",
      "142904\n",
      "142992\n",
      "143072\n",
      "143151\n",
      "143229\n",
      "143318\n",
      "143407\n",
      "143501\n",
      "143593\n",
      "143684\n",
      "143772\n",
      "143859\n",
      "143952\n",
      "144045\n",
      "144130\n",
      "144215\n",
      "144294\n",
      "144371\n",
      "144450\n",
      "144535\n",
      "144604\n",
      "144690\n",
      "144780\n",
      "144860\n",
      "144940\n",
      "145043\n",
      "145119\n",
      "145211\n",
      "145289\n",
      "145372\n",
      "145463\n",
      "145549\n",
      "145637\n",
      "145724\n",
      "145814\n",
      "145902\n",
      "145989\n",
      "146078\n",
      "146170\n",
      "146258\n",
      "146344\n",
      "146429\n",
      "146515\n",
      "146599\n",
      "146685\n",
      "146769\n",
      "146858\n",
      "146949\n",
      "147032\n",
      "147112\n",
      "147200\n",
      "147286\n",
      "147375\n",
      "147459\n",
      "147545\n",
      "147625\n",
      "147709\n",
      "147811\n",
      "147901\n",
      "147984\n",
      "148059\n",
      "148152\n",
      "148237\n",
      "148322\n",
      "148413\n",
      "148495\n",
      "148584\n",
      "148683\n",
      "148769\n",
      "148858\n",
      "148928\n",
      "149024\n",
      "149106\n",
      "149196\n",
      "149279\n",
      "149362\n",
      "149453\n",
      "149540\n",
      "149611\n",
      "149694\n",
      "149770\n",
      "149860\n",
      "149940\n",
      "150025\n",
      "# of generated data (request): 4478\n"
     ]
    }
   ],
   "source": [
    "from rankgan.model import RankGAN\n",
    "from rankgan.dataset import MSGIDSequence\n",
    "\n",
    "import util_config\n",
    "import util_data\n",
    "import data_preparation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_data(epoch_idx: int):\n",
    "    assert epoch_idx > 0\n",
    "    util_config.CONFIG.reload_param_config()\n",
    "    util_config.CONFIG.reload_path_config()\n",
    "    param_config = util_config.CONFIG.get_param_config()\n",
    "    path_config = util_config.CONFIG.get_path_config()\n",
    "\n",
    "    label_info_list = param_config['label_info_list']\n",
    "\n",
    "    train_data, train_label, _, _, _, _, _ \\\n",
    "        = data_preparation.load_data(128, label_info_list, 'before_aug', '', -1)\n",
    "\n",
    "    print(f'Train Data Info.')\n",
    "    print(f'Attack-free: {(train_label == 0).sum()}')\n",
    "    print(f'Heartbeat: {(train_label == 1).sum()}')\n",
    "    print(f'Ping: {(train_label == 2).sum()}')\n",
    "    print(f'Request: {(train_label == 3).sum()}')\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataset = MSGIDSequence(train_data, DEVICE)\n",
    "\n",
    "    n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    batch_size = 512\n",
    "    ref_batch_size = 16\n",
    "    gen_hidden_size = 64\n",
    "    dis_hidden_size = 64\n",
    "    seq_len = 128\n",
    "    gen_lr = 0.0001\n",
    "    ran_lr = 0.001\n",
    "    save_path = ''\n",
    "    n_rollouts = 4\n",
    "\n",
    "    msg_set, msg_id_counts = np.unique(train_data, return_counts=True)\n",
    "    msg_id_prob_dist = msg_id_counts / msg_id_counts.sum()\n",
    "\n",
    "    print(msg_set)\n",
    "    print(msg_id_prob_dist)\n",
    "\n",
    "    gen_pre_epochs = 1\n",
    "    dis_pre_epochs = 1\n",
    "    adv_epochs = 1\n",
    "\n",
    "    rank_gan = RankGAN(train_dataset, n_vocabs, batch_size, ref_batch_size,\n",
    "                       gen_hidden_size, dis_hidden_size, n_rollouts, seq_len,\n",
    "                       gen_lr, ran_lr, save_path,\n",
    "                       msg_set, msg_id_prob_dist, DEVICE)\n",
    "\n",
    "    # Model load\n",
    "    seq_len = 128\n",
    "    gan_type = f'Unrolled-0_wasserstein-False{param_config[\"exp_id\"]}'\n",
    "    rankgan_save_path = path_config['rankgan_model_save_dir_path_template'].format(f'{seq_len}', gan_type)\n",
    "    rankgan_generator_save_file_name = path_config['rankgan_generator_save_file_name'].format('all', epoch_idx)\n",
    "    generator_save_path = os.path.join(rankgan_save_path, rankgan_generator_save_file_name)\n",
    "    rank_gan.generator.load_state_dict(torch.load(generator_save_path))\n",
    "    print(f'{rankgan_generator_save_file_name} has been loaded.')\n",
    "\n",
    "    # Sample\n",
    "    _failure_type = 'request'\n",
    "    generated_data = []\n",
    "    counter = 0\n",
    "    while True:\n",
    "        generated_tensor, _ = rank_gan.generator.generate_samples(20000)\n",
    "        generated_tensor = generated_tensor.permute(1, 0)\n",
    "        generated_npy = generated_tensor.to('cpu').numpy()\n",
    "        generated_npy = data_preparation._filter_unique(generated_npy)\n",
    "        generated_data.append(generated_npy)\n",
    "        counter += generated_npy.shape[0]\n",
    "        print(counter)\n",
    "        if counter >= param_config['rankgan']['num_of_generated_data']:\n",
    "            break\n",
    "    generated_data = np.vstack(generated_data)\n",
    "    generated_data = data_preparation._filter_unique(generated_data)\n",
    "    print(f'# of generated data ({_failure_type}): {len(generated_data)}')\n",
    "\n",
    "    # Generated data 저장\n",
    "    additional_info = f'({epoch_idx})'\n",
    "    data_type = f\"{_failure_type}_{param_config['rankgan']['num_of_generated_data']}{additional_info}.npy\"\n",
    "    generated_data_path = path_config['rankgan_generated_data_file_path_template'].format(seq_len, gan_type, data_type)\n",
    "    util_config.make_dirs(generated_data_path)\n",
    "    np.save(generated_data_path, generated_data)\n",
    "\n",
    "\n",
    "generate_data(19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StepGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info.\n",
      "Attack-free: 0\n",
      "Heartbeat: 0\n",
      "Ping: 0\n",
      "Request: 149797\n",
      "D:/tasks/Projects/2022/무인이동체/논문작업/hitl\\data2/model_save/stepgan/1.0_128/Unrolled-0_wasserstein-False(step1)\\adv_trained_gen_all_19\n",
      "adv_trained_gen_all_19 has been loaded.\n",
      "# of generated data (request): 50175\n"
     ]
    }
   ],
   "source": [
    "from stepgan.dataset import MSGIDSequence, X_LEN, Y_LEN\n",
    "from stepgan.model import StepGAN\n",
    "\n",
    "import util_data\n",
    "import util_config\n",
    "import data_preparation\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def generate_data(epoch_idx: int):\n",
    "    assert epoch_idx > 0\n",
    "    util_config.CONFIG.reload_param_config()\n",
    "    util_config.CONFIG.reload_path_config()\n",
    "    param_config = util_config.CONFIG.get_param_config()\n",
    "    path_config = util_config.CONFIG.get_path_config()\n",
    "\n",
    "    seq_len = 128\n",
    "\n",
    "    label_info_list = param_config['label_info_list']\n",
    "    train_data, train_label, _, _, _, _, _ \\\n",
    "        = data_preparation.load_data(seq_len, label_info_list, 'before_aug', '', -1)\n",
    "\n",
    "    \"\"\"\n",
    "    filtered_train_data = [train_data[(train_label == 0) | (train_label == 1)]]\n",
    "    filtered_train_label = [train_label[(train_label == 0) | (train_label == 1)]]\n",
    "\n",
    "    ping_data = train_data[train_label == 2]\n",
    "    ping_label = train_label[train_label == 2]\n",
    "    perm = np.random.permutation(ping_data.shape[0])\n",
    "    ping_data = ping_data[perm][:2000]\n",
    "    ping_label = ping_label[perm][:2000]\n",
    "    filtered_train_data.append(ping_data)\n",
    "    filtered_train_label.append(ping_label)\n",
    "\n",
    "    request_data = train_data[train_label == 3]\n",
    "    request_label = train_label[train_label == 3]\n",
    "    perm = np.random.permutation(request_data.shape[0])\n",
    "    request_data = request_data[perm][:2000]\n",
    "    request_label = request_label[perm][:2000]\n",
    "    filtered_train_data.append(request_data)\n",
    "    filtered_train_label.append(request_label)\n",
    "\n",
    "    train_data = np.vstack(filtered_train_data)\n",
    "    train_label = np.hstack(filtered_train_label)\n",
    "    \"\"\"\n",
    "    _failure_type = 'request'\n",
    "\n",
    "    print(f'Train Data Info.')\n",
    "    print(f'Attack-free: {(train_label == 0).sum()}')\n",
    "    print(f'Heartbeat: {(train_label == 1).sum()}')\n",
    "    print(f'Ping: {(train_label == 2).sum()}')\n",
    "    print(f'Request: {(train_label == 3).sum()}')\n",
    "\n",
    "    one_hot_label_list = []\n",
    "    for label in train_label:\n",
    "        one_hot_label = np.zeros(4)\n",
    "        one_hot_label[int(label)] = 1.0\n",
    "        one_hot_label_list.append(one_hot_label)\n",
    "    train_label = np.vstack(one_hot_label_list)\n",
    "\n",
    "    msg_id_sequence = MSGIDSequence(train_data, train_label, DEVICE)\n",
    "\n",
    "    batch_size = 512\n",
    "    gen_hidden_size = 64\n",
    "    dis_hidden_size = 64\n",
    "    gen_lr = 0.0001\n",
    "    dis_lr = 0.005\n",
    "    enc_seq_len = X_LEN\n",
    "    dec_seq_len = Y_LEN\n",
    "    gen_pre_epochs = 1\n",
    "    dis_pre_epochs = 1\n",
    "    adv_epochs = 1\n",
    "    n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    save_path = ''\n",
    "    train_dataset = msg_id_sequence\n",
    "\n",
    "    # Model\n",
    "    step_gan = StepGAN(train_dataset, len(label_info_list), n_vocabs, batch_size, gen_hidden_size, dis_hidden_size,\n",
    "                       gen_lr, dis_lr, enc_seq_len, dec_seq_len, save_path, DEVICE)\n",
    "\n",
    "    # Model load\n",
    "    gan_type = f'Unrolled-0_wasserstein-False{param_config[\"exp_id\"]}'\n",
    "    stepgan_save_path = path_config['stepgan_model_save_dir_path_template'].format(f'{seq_len}', gan_type)\n",
    "    stepgan_generator_save_file_name = path_config['stepgan_generator_save_file_name'].format('all', epoch_idx)\n",
    "    generator_save_path = os.path.join(stepgan_save_path, stepgan_generator_save_file_name)\n",
    "    print(generator_save_path)\n",
    "    step_gan.generator.load_state_dict(torch.load(generator_save_path))\n",
    "    print(f'{stepgan_generator_save_file_name} has been loaded.')\n",
    "\n",
    "    valid_n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    # Sample\n",
    "    generated_data = []\n",
    "    counter = 0\n",
    "    for x_tensor, y_tensor, label_tensor in step_gan.train_dataloader:\n",
    "        generated_tensor, _ \\\n",
    "            = step_gan.generator.sample_data(x_tensor, y_tensor, label_tensor)\n",
    "        generated_tensor = torch.hstack([x_tensor, generated_tensor])\n",
    "        \n",
    "        generated_npy = generated_tensor.to('cpu').numpy()\n",
    "        generated_data.append(generated_npy)\n",
    "\n",
    "        counter += generated_npy.shape[0]\n",
    "        if counter >= param_config['stepgan_model']['num_of_generated_data']:\n",
    "            break\n",
    "    generated_data = np.vstack(generated_data)\n",
    "    generated_data = data_preparation._filter_unique(generated_data)\n",
    "    print(f'# of generated data ({_failure_type}): {len(generated_data)}')\n",
    "\n",
    "    # Generated data 저장\n",
    "    additional_info = f'({epoch_idx})'\n",
    "    data_type = f\"{_failure_type}_{param_config['leakgan_model']['num_of_generated_data']}{additional_info}.npy\"\n",
    "    generated_data_path = path_config['leakgan_generated_data_file_path_template'].format(seq_len, gan_type, data_type)\n",
    "    util_config.make_dirs(generated_data_path)\n",
    "    np.save(generated_data_path, generated_data)\n",
    "\n",
    "\n",
    "generate_data(19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeakGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info.\n",
      "Attack-free: 158730\n",
      "Heartbeat: 159795\n",
      "Ping: 159723\n",
      "Request: 149797\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 18 19 20 21 22 23 24 25 26 27]\n",
      "[0.00213425 0.00213303 0.00213426 0.21975201 0.19948206 0.02716992\n",
      " 0.0357983  0.07856859 0.078656   0.0448746  0.0160769  0.0295594\n",
      " 0.02042431 0.03269328 0.02114356 0.07877068 0.02115052 0.04204499\n",
      " 0.0210471  0.00106922 0.01000146 0.00999583 0.00107055 0.0042492 ]\n",
      "adv_trained_gen_all_0 has been loaded.\n",
      "adv_trained_dis_all_0 has been loaded.\n",
      "# of generated data (ping(2)): 50000\n",
      "# of generated data (request(3)): 50000\n"
     ]
    }
   ],
   "source": [
    "from leakgan.model import LeakGAN\n",
    "from leakgan.dataset import MSGIDSequence\n",
    "\n",
    "import util_config\n",
    "import util_data\n",
    "import data_preparation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_data(epoch_idx: int):\n",
    "    util_config.CONFIG.reload_param_config()\n",
    "    util_config.CONFIG.reload_path_config()\n",
    "    param_config = util_config.CONFIG.get_param_config()\n",
    "    path_config = util_config.CONFIG.get_path_config()\n",
    "\n",
    "    labels_to_generate = param_config['leakgan_model']['labels_to_generate']\n",
    "    seq_len = 128\n",
    "\n",
    "    label_info_list = param_config['label_info_list']\n",
    "    train_data, train_label, _, _, _, _, _ \\\n",
    "        = data_preparation.load_data(128, label_info_list, 'before_aug_none', '')\n",
    "\n",
    "    print(f'Train Data Info.')\n",
    "    print(f'Attack-free: {(train_label == 0).sum()}')\n",
    "    print(f'Heartbeat: {(train_label == 1).sum()}')\n",
    "    print(f'Ping: {(train_label == 2).sum()}')\n",
    "    print(f'Request: {(train_label == 3).sum()}')\n",
    "\n",
    "    one_hot_label_list = []\n",
    "    for label in train_label:\n",
    "        one_hot_label = np.zeros(len(labels_to_generate))\n",
    "        one_hot_label[int(label)] = 1.0\n",
    "        one_hot_label_list.append(one_hot_label)\n",
    "    train_label = np.vstack(one_hot_label_list)\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataset = MSGIDSequence(train_data, train_label, DEVICE)\n",
    "\n",
    "    n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    batch_size = 1024\n",
    "    gen_hidden_size = 64\n",
    "    dis_hidden_size = 64\n",
    "    seq_len = 128\n",
    "    gen_lr = 0.0001\n",
    "    dis_lr = 0.001\n",
    "    save_path = ''\n",
    "    n_rollouts = 1\n",
    "\n",
    "    msg_set, msg_id_counts = np.unique(train_data, return_counts=True)\n",
    "    msg_id_prob_dist = msg_id_counts / msg_id_counts.sum()\n",
    "\n",
    "    print(msg_set)\n",
    "    print(msg_id_prob_dist)\n",
    "\n",
    "    gen_pre_epochs = 1\n",
    "    dis_pre_epochs = 1\n",
    "    adv_epochs = 1\n",
    "\n",
    "    leak_gan = LeakGAN(train_dataset, n_vocabs, len(label_info_list), batch_size,\n",
    "                       gen_hidden_size, dis_hidden_size, n_rollouts, seq_len,\n",
    "                       gen_lr, dis_lr, save_path,\n",
    "                       msg_set, msg_id_prob_dist, DEVICE)\n",
    "\n",
    "    # Model load\n",
    "    seq_len = 128\n",
    "    gan_type = f'Unrolled-0_wasserstein-False{param_config[\"exp_id\"]}'\n",
    "    leakgan_save_path = path_config['leakgan_model_save_dir_path_template'].format(f'{seq_len}', gan_type)\n",
    "    leakgan_generator_save_file_name = path_config['leakgan_generator_save_file_name'].format('all', epoch_idx)\n",
    "    generator_save_path = os.path.join(leakgan_save_path, leakgan_generator_save_file_name)\n",
    "    leak_gan.generator.load_state_dict(torch.load(generator_save_path))\n",
    "    print(f'{leakgan_generator_save_file_name} has been loaded.')\n",
    "\n",
    "    leakgan_discriminator_save_file_name = path_config['leakgan_discriminator_save_file_name'].format('all', epoch_idx)\n",
    "    discriminator_save_path = os.path.join(leakgan_save_path, leakgan_discriminator_save_file_name)\n",
    "    leak_gan.discriminator.load_state_dict(torch.load(discriminator_save_path))\n",
    "    print(f'{leakgan_discriminator_save_file_name} has been loaded.')\n",
    "\n",
    "    # Sample\n",
    "    valid_n_vocabs = len(util_data.INT_TO_MSG_ID_CONVERTER)\n",
    "    # Sample\n",
    "    for idx, _failure_type in enumerate(labels_to_generate):\n",
    "        if idx == 0 or idx == 1:\n",
    "            continue\n",
    "        generated_data = []\n",
    "        counter = 0\n",
    "\n",
    "        one_hot_label = np.zeros(len(labels_to_generate))\n",
    "        one_hot_label[int(idx)] = 1.0\n",
    "        one_hot_labels = np.repeat([one_hot_label], 1000, 0)\n",
    "        label_tensor = torch.Tensor(one_hot_labels).to(DEVICE)\n",
    "\n",
    "        while True:\n",
    "            generated_tensor = leak_gan.generate_samples(label_tensor)\n",
    "            generated_npy = generated_tensor.to('cpu').numpy()\n",
    "            generated_npy = generated_npy[(generated_npy >= len(util_data.INT_TO_MSG_ID_CONVERTER)).sum(1) == 0]\n",
    "            generated_data.append(generated_npy)\n",
    "\n",
    "            counter += generated_npy.shape[0]\n",
    "            if counter >= param_config['leakgan_model']['num_of_generated_data']:\n",
    "                break\n",
    "        generated_data = np.vstack(generated_data)\n",
    "        generated_data = data_preparation._filter_unique(generated_data)\n",
    "        print(f'# of generated data ({_failure_type}({idx})): {len(generated_data)}')\n",
    "    \n",
    "        # Generated data 저장\n",
    "        additional_info = f'({epoch_idx})'\n",
    "        data_type = f\"{_failure_type}_{param_config['leakgan_model']['num_of_generated_data']}{additional_info}.npy\"\n",
    "        generated_data_path = path_config['leakgan_generated_data_file_path_template'].format(seq_len, gan_type, data_type)\n",
    "        util_config.make_dirs(generated_data_path)\n",
    "        np.save(generated_data_path, generated_data)\n",
    "\n",
    "\n",
    "generate_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26a6b83dea231e1d1e9a053dc56fbc476848ab280a295687552b551346799e6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('uavproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
